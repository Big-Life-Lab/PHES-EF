---
title: "e-Delphi Study"

bibliography: references.bib
---

::: justify-text
A Delphi technique will be used to develop an internationally accepted evaluation framework for public health environmental surveillance. The Delphi method is an iterative multi-round approach that uses a series of sequential surveys, interspersed by controlled feedback, to elicit consensus among a group of individuals while maintaining anonymity [@shang2023; @niederberger2020]. An electronic Delphi (e-Delphi) method will be used to overcome geographic barriers and allow us to engage panellists internationally across various time zones.

The study protocol is currently in publication with PLOS One. However, the pre-print is available on [MedRxiv](https://www.medrxiv.org/content/10.1101/2024.09.01.24312901v1).

## Recruitment of Panelists

We will recruit a multinational, multidisciplinary panel of wastewater-based surveillance experts, knowledge users, and engaged members of the public to complete the e-Delphi survey. Panellists will be selected to capture the multiple perspectives of those that influence the design, implementation, evaluation, use, and reporting of wastewater surveillance activities, including the following subdisciplines groups: public health, infectious disease, epidemiology; environmental and physical sciences; mathematical sciences; social sciences; and communication, knowledge translation and exchange.

we will aim to recruit at least 50 panellists. Preferably, with at least 8-10 people per discipline subgroup. The study working group will monitor the distribution of registered panellists based on their demographic information and will try to distribute appropriately across discipline subgroups and other demographic markers.

### Eligibility Criteria for e-Delphi Survey Panellists

::: {.table-striped}
```{r table-eligibility-criteria, echo=FALSE, warning=FALSE}

# Load the gt package
library(gt)

# Create a data frame with your data
data <- data.frame(
  Discipline = c("Public health, infectious disease, epidemiology <br><br>Environmental and physical science <br><br>Mathematical sciences <br><br>Social sciences <br><br>Communication, knowledge translation and Exchange", 
    "Knowledge users", 
    "Engaged public"
  ),
  Inclusion_Criteria = c(
    "An adult^*1*^ who is proficient in English and has a graduate degree in one of the listed specializations^*2*^, or ≥ 3 years of professional experience, or ≥ 2 peer-reviewed publications relating to wastewater surveillance.",
    "An adult^*1*^ who is proficient in English and who is a professional who does not have specialized training or qualifications in wastewater-based surveillance, but who uses surveillance to inform policy and action in their workplace.",
    "An adult^*1*^ who is proficient in English and has relevant lived experience."
  )
)

# Generate the table using gt
gt(data, id = "delphi_table") %>%
   fmt_markdown() %>%
  cols_width(Discipline ~ "30%") %>%
    cols_label(
    Discipline = "Discipline subgroup", 
    Inclusion_Criteria = "Inclusion criteria"
  ) %>%
 tab_source_note(source_note = md(
    c("^*1*^ Adult: ≥ 18 years of age.",
      "^*2*^ The list of specializations associated with each discipline can be found in the S2 Table of the study protocol once published.")
  ))

```
:::

**Definitions**

*Professional experience:* Paid employment or professional practice in a listed specialization (current or former). *Graduate or professional degree:* Master or PhD in a listed discipline/specialization.

## Procedure

We will conduct a two-round e-Delphi survey to generate consensus on evaluation criteria (Figure 2). Summaries of Round 1 will be compiled for the subsequent round. Custom survey pathways will be generated for each stakeholder group (i.e., panellists from different stakeholder groups will be shown a different collection of candidate items). Within each custom stakeholder survey pathway, panellists will also have the option to skip items or self-declare that they are not qualified to assess certain candidate items.

### Round 1

Panellists will be invited to rate their level of agreement with candidate items generated from scoping review results and consultation with the study executive group. Free-text boxes will be included for panellists to provide feedback or identify additional candidate items to be included in the next e-Delphi survey round. 

### Round 2

Regardless of whether they participated in the previous round, panellists will be invited to participate in Round 2 of the e-Delphi survey. All panellists will be invited to rate new items and re-rate previous items that did not reach consensus. When re-rating their level of agreement, panellists will be presented with their previous round scores alongside the aggregate group results. Anonymous feedback from Round 1 will also be compiled and presented during Round 2.  Any newly suggested items during Round 2 will be deliberated on during the consensus meeting.

### Defining Consensus

Candidate items will be assessed on the following four rating properties: (1) relevance and practical utility; (2) scientific rigor, validity and reliability; (3) feasibility, adaptability and resource implications; and (4) equity, inclusiveness, and mitigation of bias. 

A 7-point Likert scale (1 = highly irrelevant to 7 = highly relevant) will be used to rate each property for all candidate items. A summary score for each candidate item will be created by calculating the median of the four property ratings. Panellist summary scores will then be categorised as excluded item (irrelevant: 1–2), further discussion (equivocal: 3–5), or core item (relevant: 6–7). Consensus for each item is defined as ≥ 70% of the panellist votes falling within the same category (1–2, 3–5, or 6–7). 

The approach to use a 7-point fully-labeled Likert scale – a higher number of categories compared to many studies – is informed by the consideration that panellists are professionals and engaged members of the public with good cognitive skills; therefore, more categories and labels will be more discriminating and reproducible [@diamond2014; @belton2019; @weijters2010; @lange2020]. The ≥ 70% consensus cut-off – a lower cut-off compared to many studies – is informed by the rapidly evolving nature of environmental surveillance for public health and the wide range of disciplines invited to the panel; therefore, a high level of agreement may not occur [@diamond2014; @belton2019; @weijters2010; @lange2020].

![](assets/delphi_consensus_process.svg){fig-align="center" width=100%}
[**Figure 2.** E-Delphi onsensus process for the Public Health Environmental Surveillance Evaluation Framework (PHES-EF)]{.caption}

## References

::: {#refs}
:::
:::
